# token
i learn here how to use nannoGPT and document the process. it is basically encoding characters into a matrix. that is a tensor and requires tokens and sequences. a comprehension of python and matrix manipulation is required. Google Colab Juypeter Notebook used. Codebook size and sequence length is inversely proportional; a codebook is a vocabulary. A vocabulary is an encoding of characters into integers. EX. A=0 B=1 C=1; [0,1,2] decode = ABC. End ex. A character level tokenizer is simple. Best practice is subword-level-tokens. Simple means small codebook and simple encode and decode functions; sequences will be very long. A tensor is a multi-dimensional array that can be of any shape or size. It is similar to a mathematical vector or matrix but can have more dimensions. Tensors are fundamental data structures in deep learning and are used to store and manipulate the data involved in training and inference processes. The TorchTensor class in PyTorch represents a tensor and provides various operations and methods for manipulating tensor data. Tensors can store numerical data, such as floating-point numbers, integers, or even boolean values. They can be used to represent inputs, outputs, and intermediate representations in neural networks. PyTorch provides a rich set of functions and operations that can be performed on TorchTensors, including mathematical operations, indexing, slicing, reshaping, and more. Additionally, PyTorch integrates seamlessly with GPUs, enabling accelerated computation on parallel hardware, which is crucial for deep learning tasks.
